{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFlowCAM → EcoTaxa converter (single sample version)\\n---------------------------------------------------\\nThis script processes a single FlowCAM sample folder containing:\\n - one .lst file\\n - corresponding image files\\n\\nIt reads the sample metadata from an Excel file, injects it into the EcoTaxa\\nobject table, and outputs a zipped EcoTaxa-compatible archive (.zip)\\ncontaining the .tsv file and images.\\n\\nBefore running:\\n1. Install dependencies:\\n   pip install morphocut pandas openpyxl tqdm\\n\\n2. Edit the paths below to match your setup.\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "FlowCAM → EcoTaxa converter (single sample version)\n",
    "---------------------------------------------------\n",
    "This script processes a single FlowCAM sample folder containing:\n",
    " - one .lst file\n",
    " - corresponding image files\n",
    "\n",
    "It reads the sample metadata from an Excel file, injects it into the EcoTaxa\n",
    "object table, and outputs a zipped EcoTaxa-compatible archive (.zip)\n",
    "containing the .tsv file and images.\n",
    "\n",
    "Before running:\n",
    "1. Install dependencies:\n",
    "   pip install morphocut pandas openpyxl tqdm\n",
    "\n",
    "2. Edit the paths below to match your setup.\n",
    "\"\"\"\n",
    "# ok so here it is - my final code, made after many hours of talking with chatGPT : )\n",
    "# it should work, but the only for one sample per processing\n",
    "# the paths to the sample, to the file for final product , and to the metadata excel file should be defined\n",
    "# remmember to prepare proper excel sheet with metadata in EcoTaxa style (object_; sample_; acq_; etc)\n",
    "#author: Adam Makatun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "from morphocut.core import Pipeline\n",
    "from morphocut.file import Find\n",
    "from morphocut.integration.flowcam import FlowCamReader\n",
    "from morphocut.image import RGB2Gray, ImageProperties\n",
    "from morphocut.stream import TQDM\n",
    "from morphocut.str import Format\n",
    "from morphocut.contrib.ecotaxa import EcotaxaWriter\n",
    "from morphocut.contrib.zooprocess import CalculateZooProcessFeatures\n",
    "import zipfile\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === USER SETTINGS ==========================================================\n",
    "\n",
    "# Path to the folder with one FlowCAM sample (contains .lst and images)\n",
    "input_folder = Path(\"F:/FlowCam/testujemy/FC_file\")\n",
    "\n",
    "# Path to the metadata Excel file\n",
    "metadata_file = Path(\"F:/FlowCam/testujemy/meta.xlsx\")\n",
    "\n",
    "# Output .zip file path (will contain EcoTaxa .tsv + images)\n",
    "output_file = Path(\"F:/FlowCam/testujemy/done/test.zip\")\n",
    "\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample: ZGG_20-0m_FC300_2\n",
      "Matched metadata: {'sample_id': 'ZGG_20-0m_FC300_2', 'sample_ship': 'r/v Oceanograf', 'sample_operator': 'Adam Makatun', 'sample_sampling_gear': 'MultiNet/100', 'sample_season': 'summer', 'sample_total_volume_m3': 9, 'sample_concentrated_sample_volume_ml': 25, 'sample_dilution_factor': 0.5, 'acq_instrument': 'FlowCAM VS-IV', 'acq_celltype': 'FC300', 'acq_volume_ml': 4.194, 'acq_imaged_volume_ml': 1.7437, 'object_lat': 54.8336886, 'object_lon': 19.29635, 'acq_id': 1}\n"
     ]
    }
   ],
   "source": [
    "# --- Load metadata and create a dictionary ----------------------------------\n",
    "metadata_df = pd.read_excel(metadata_file)\n",
    "\n",
    "# Ensure consistent column naming\n",
    "metadata_df.columns = [str(c).strip() for c in metadata_df.columns]\n",
    "\n",
    "# --- Detect .lst file and extract sample_id ---------------------------------\n",
    "lst_files = list(input_folder.glob(\"*.lst\"))\n",
    "if len(lst_files) == 0:\n",
    "    raise FileNotFoundError(f\"No .lst file found in {input_folder}\")\n",
    "if len(lst_files) > 1:\n",
    "    print(f\"⚠️ Multiple .lst files found, using the first one: {lst_files[0].name}\")\n",
    "\n",
    "lst_file = lst_files[0]\n",
    "sample_id = lst_file.stem  # filename without extension\n",
    "\n",
    "# --- Extract matching metadata row ------------------------------------------\n",
    "meta_row = metadata_df.loc[metadata_df[\"sample_id\"] == sample_id]\n",
    "if meta_row.empty:\n",
    "    raise ValueError(f\"Sample ID '{sample_id}' not found in metadata Excel.\")\n",
    "metadata_dict = meta_row.iloc[0].to_dict()\n",
    "\n",
    "print(f\"Processing sample: {sample_id}\")\n",
    "print(f\"Matched metadata: {metadata_dict}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file.parent.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: DeprecationWarning: Call to deprecated function (or staticmethod) TQDM. (Deprecated in favor of Progress.) -- Deprecated since version 0.2.x.\n",
      "ZGG_20-0m_FC300_2_10000: 100%|████████████████████████████████████████████████████| 10.0k/10.0k [01:42<00:00, 97.4it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EcotaxaWriter: Wrote 10,000 entries to ecotaxa_export.tsv.\n",
      "EcotaxaWriter: Wrote 10,000 objects to F:\\FlowCam\\testujemy\\done\\test.zip.\n",
      "\n",
      "✅ Done! EcoTaxa archive created at:\n",
      "F:\\FlowCam\\testujemy\\done\\test.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Run MorphoCut pipeline --------------------------------------------------\n",
    "with Pipeline() as p:\n",
    "    # Find the .lst file (only one expected)\n",
    "    lst_fn = Find(str(input_folder), [\".lst\"])\n",
    "\n",
    "    # Read FlowCAM data\n",
    "    obj = FlowCamReader(lst_fn)\n",
    "\n",
    "    # Extract image and mask\n",
    "    img = obj.image\n",
    "    mask = obj.mask\n",
    "    img_gray = RGB2Gray(img, True)\n",
    "\n",
    "    # Copy FlowCAM object metadata\n",
    "    object_meta = obj.data\n",
    "\n",
    "    # Construct object ID\n",
    "    object_id = Format(\"{lst_name}_{id}\", lst_name=obj.lst_name, _kwargs=object_meta)\n",
    "    object_meta[\"id\"] = object_id\n",
    "\n",
    "    # Extract region properties (size, shape, etc.)\n",
    "    regionprops = ImageProperties(mask, img_gray)\n",
    "\n",
    "    # Calculate ZooProcess-like features\n",
    "    object_meta = CalculateZooProcessFeatures(regionprops, object_meta)\n",
    "\n",
    "\n",
    "    # Write to EcoTaxa .zip\n",
    "    EcotaxaWriter(\n",
    "        str(output_file),\n",
    "        [(Format(\"{object_id}.jpg\", object_id=object_id), img)],\n",
    "        object_meta=object_meta,\n",
    "    )\n",
    "\n",
    "    # Add progress bar\n",
    "    TQDM(object_id)\n",
    "\n",
    "# Execute the pipeline\n",
    "p.run()\n",
    "\n",
    "print(f\"\\n✅ Done! EcoTaxa archive created at:\\n{output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to add the metadata to the .tsv file (unfortunatelly, I could not do that in the morphocut pipeline - somhow it is not working)\n",
    "\n",
    "# Paths\n",
    "zip_path = r\"F:/FlowCam/testujemy/done/test.zip\"\n",
    "metadata_file = r\"F:/FlowCam/testujemy/meta.xlsx\"\n",
    "# Load Excel metadata and set sample_id as index\n",
    "meta_df = pd.read_excel(metadata_file).set_index(\"sample_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected sample ID: ZGG_20-0m_FC300_2\n",
      "✅ Updated TSV inside zip: F:/FlowCam/testujemy/done/test.zip\n"
     ]
    }
   ],
   "source": [
    "# Open zip and read TSV\n",
    "with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "    tsv_name = [f for f in z.namelist() if f.endswith(\".tsv\")][0]\n",
    "    tsv_bytes = z.read(tsv_name)\n",
    "    \n",
    "    # Keep other files (images) in memory\n",
    "    other_files = {f: z.read(f) for f in z.namelist() if f != tsv_name}\n",
    "\n",
    "# Read TSV as text to preserve headers\n",
    "lines = tsv_bytes.decode(\"utf-8\").splitlines()\n",
    "header = lines[0].split(\"\\t\")\n",
    "types = lines[1].split(\"\\t\")\n",
    "data_lines = lines[2:]\n",
    "\n",
    "# Remove 'object_label' if present\n",
    "if \"object_label\" in header:\n",
    "    idx = header.index(\"object_label\")\n",
    "    header.pop(idx)\n",
    "    types.pop(idx)\n",
    "    data_lines = [\"\\t\".join([v for i, v in enumerate(line.split(\"\\t\")) if i != idx]) for line in data_lines]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame([line.split(\"\\t\") for line in data_lines], columns=header)\n",
    "\n",
    "# Extract sample_id from object_id (assumes format: sampleID_something)\n",
    "sample_id = df['object_id'].iloc[0].rsplit(\"_\", 1)[0]\n",
    "print(\"Detected sample ID:\", sample_id)\n",
    "\n",
    "# Get Excel metadata for this sample\n",
    "if sample_id not in meta_df.index:\n",
    "    raise ValueError(f\"Sample ID '{sample_id}' not found in metadata Excel\")\n",
    "new_metadata = meta_df.loc[sample_id].to_dict()\n",
    "\n",
    "# Add sample_id as a new column\n",
    "df['sample_id'] = sample_id\n",
    "header.append('sample_id')\n",
    "types.append(\"[t]\")  # treat as string\n",
    "\n",
    "# Add Excel metadata as new columns\n",
    "for col, val in new_metadata.items():\n",
    "    df[col] = str(val)\n",
    "    header.append(col)\n",
    "    types.append(\"[t]\" if isinstance(val, str) else \"[f]\")\n",
    "\n",
    "# Ensure all data are strings\n",
    "df = df.astype(str)\n",
    "\n",
    "# Write updated TSV back into a BytesIO\n",
    "tsv_buffer = BytesIO()\n",
    "tsv_buffer.write((\"\\t\".join(header) + \"\\n\").encode(\"utf-8\"))\n",
    "tsv_buffer.write((\"\\t\".join(types) + \"\\n\").encode(\"utf-8\"))\n",
    "for _, row in df.iterrows():\n",
    "    tsv_buffer.write((\"\\t\".join(row) + \"\\n\").encode(\"utf-8\"))\n",
    "tsv_buffer.seek(0)\n",
    "\n",
    "# Recreate zip with updated TSV and original images\n",
    "with zipfile.ZipFile(zip_path, 'w') as z:\n",
    "    # Add updated TSV\n",
    "    z.writestr(tsv_name, tsv_buffer.read())\n",
    "    # Add other original files\n",
    "    for f, content in other_files.items():\n",
    "        z.writestr(f, content)\n",
    "\n",
    "print(f\"✅ Updated TSV inside zip: {zip_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
